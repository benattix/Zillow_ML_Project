{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MIDS W207 Final</h1>\n",
    "\n",
    "<h3> Group Members </h3>\n",
    "Ben Attix <br>\n",
    "Justin Plumley <br>\n",
    "Dan Watson\n",
    "\n",
    "<h3> Kaggle Competition </h3>\n",
    "Zillow Prize: Zillow’s Home Value Prediction (Zestimate)\n",
    "\n",
    "<h3> Evaluation </h3>\n",
    "Submissions are evaluated on Mean Absolute Error between the predicted log error and the actual log error. The log error is defined as:\n",
    "logerror=log(Zestimate)−log(SalePrice)\n",
    "and it is recorded in the transactions training data. If a transaction didn't happen for a property during that period of time, that row is ignored and not counted in the calculation of MAE.\n",
    "\n",
    "<h5> Competition Website </h5>\n",
    "https://www.kaggle.com/c/zillow-prize-1#description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Load libraries, data, and test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# General libraries.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "color = sns.color_palette()\n",
    "import time\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 58)\n",
      "(90275, 3)\n"
     ]
    }
   ],
   "source": [
    "train_csv = pd.read_csv(\"train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n",
    "prop_df = pd.read_csv(\"properties_2016.csv\")\n",
    "print prop_df.shape \n",
    "print train_csv.shape\n",
    "#df outputs\n",
    "#prop_df.head()\n",
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11016594</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14366692</td>\n",
       "      <td>-0.1684</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12098116</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12643413</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>2016-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14432541</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>2016-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror transactiondate\n",
       "0  11016594    0.0276      2016-01-01\n",
       "1  14366692   -0.1684      2016-01-01\n",
       "2  12098116   -0.0040      2016-01-01\n",
       "3  12643413    0.0218      2016-01-02\n",
       "4  14432541   -0.0050      2016-01-02"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> EDA </H2> <br>\n",
    "Many ideas and code taken from following EDA Kernels:\n",
    "https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize (python)\n",
    "https://www.kaggle.com/philippsp/exploratory-analysis-zillow (R)\n",
    "https://www.kaggle.com/captcalculator/a-very-extensive-zillow-exploratory-analysis (R)\n",
    "https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity (python)\n",
    "\n",
    "<H5> Start by looking at the parcelIDs that occur in each dataset </H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start by looing at unique parcelIDs\n",
    "print \"Unique ParcelIDs in train_df:\", train_csv.parcelid.nunique()\n",
    "print \"Unique ParcelIDs in prop_df:\", prop_df.parcelid.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2,985,217 parcel IDs in the properties data but only 90,150 in the training data. When training our model, the only parcel IDs we can use are the ones both datasets, the rest are useless to us.\n",
    "\n",
    "By doing an inner merge we can limit our data down to the parcel IDs we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (90275, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11016594</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122754.0</td>\n",
       "      <td>360170.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>237416.0</td>\n",
       "      <td>6735.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037107e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14366692</td>\n",
       "      <td>-0.1684</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346458.0</td>\n",
       "      <td>585529.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>239071.0</td>\n",
       "      <td>10153.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12098116</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61994.0</td>\n",
       "      <td>119906.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>57912.0</td>\n",
       "      <td>11484.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037464e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12643413</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171518.0</td>\n",
       "      <td>244880.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>73362.0</td>\n",
       "      <td>3048.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.037296e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14432541</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169574.0</td>\n",
       "      <td>434551.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>264977.0</td>\n",
       "      <td>5488.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.059042e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror transactiondate  airconditioningtypeid  \\\n",
       "0  11016594    0.0276      2016-01-01                    1.0   \n",
       "1  14366692   -0.1684      2016-01-01                    NaN   \n",
       "2  12098116   -0.0040      2016-01-01                    1.0   \n",
       "3  12643413    0.0218      2016-01-02                    1.0   \n",
       "4  14432541   -0.0050      2016-01-02                    NaN   \n",
       "\n",
       "   architecturalstyletypeid  basementsqft  bathroomcnt  bedroomcnt  \\\n",
       "0                       NaN           NaN          2.0         3.0   \n",
       "1                       NaN           NaN          3.5         4.0   \n",
       "2                       NaN           NaN          3.0         2.0   \n",
       "3                       NaN           NaN          2.0         2.0   \n",
       "4                       NaN           NaN          2.5         4.0   \n",
       "\n",
       "   buildingclasstypeid  buildingqualitytypeid         ...           \\\n",
       "0                  NaN                    4.0         ...            \n",
       "1                  NaN                    NaN         ...            \n",
       "2                  NaN                    4.0         ...            \n",
       "3                  NaN                    4.0         ...            \n",
       "4                  NaN                    NaN         ...            \n",
       "\n",
       "   numberofstories  fireplaceflag  structuretaxvaluedollarcnt  \\\n",
       "0              NaN            NaN                    122754.0   \n",
       "1              NaN            NaN                    346458.0   \n",
       "2              NaN            NaN                     61994.0   \n",
       "3              NaN            NaN                    171518.0   \n",
       "4              2.0            NaN                    169574.0   \n",
       "\n",
       "   taxvaluedollarcnt  assessmentyear  landtaxvaluedollarcnt  taxamount  \\\n",
       "0           360170.0          2015.0               237416.0    6735.88   \n",
       "1           585529.0          2015.0               239071.0   10153.02   \n",
       "2           119906.0          2015.0                57912.0   11484.48   \n",
       "3           244880.0          2015.0                73362.0    3048.74   \n",
       "4           434551.0          2015.0               264977.0    5488.96   \n",
       "\n",
       "   taxdelinquencyflag  taxdelinquencyyear  censustractandblock  \n",
       "0                 NaN                 NaN         6.037107e+13  \n",
       "1                 NaN                 NaN                  NaN  \n",
       "2                 NaN                 NaN         6.037464e+13  \n",
       "3                 NaN                 NaN         6.037296e+13  \n",
       "4                 NaN                 NaN         6.059042e+13  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframes and view result\n",
    "train_df = pd.merge(train_csv, prop_df, on='parcelid', how='inner')\n",
    "print 'Dataframe shape:', train_df.shape\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(range(train_df.shape[0]), np.sort(train_df.logerror.values))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('logerror', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log error is quite good for vast majority- outliers are key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.logerror.values, bins=50, kde=False)\n",
    "plt.xlabel('logerror', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems liked a peaked distribution, but outliers on log error are affecting the histogram.  Removing outliers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<H5> Transaction Date </H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.transactiondate.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All the data is from 2016- we can aggregate it by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAucAAAF6CAYAAAC6F/bIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagnDuSRJktQShnNJkiSpJf4/zY+YIG61QvgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1081a3850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['transaction_month'] = train_df['transactiondate'].dt.month\n",
    "\n",
    "cnt_srs = train_df['transaction_month'].value_counts()\n",
    "plt.figure(figsize=(12,6))\n",
    "bars= sns.barplot(cnt_srs.index, cnt_srs.values,  color=color[2])\n",
    "plt.xticks()\n",
    "plt.xlabel('Month of transaction', fontsize=12)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slow start of the year, then transactions pick up through August.  We do not have all the transactions after October 15th, per competition website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "s1_dims = (15, 20)\n",
    "fig, ax = plt.subplots(figsize=s1_dims)\n",
    "ax.set(ylim=(-0.2, 0.2))\n",
    "sns.violinplot(ax=ax, data=train_df, x=\"transaction_month\", y=\"logerror\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance appears to grow with the later months (those with fewer values), though the medians appear to be positive, particularly for the winter months.  Besides normal features, we may want to include dummy variables for seasonality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h5> Parcel ID </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['parcelid'].value_counts().reset_index()['parcelid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Only 124 of the 90k+ properties had multiple transactions in this year period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<H5> Onto the Properties 2016 file <H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAQPCAYAAAADP2MvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b18b4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "\n",
    "ind = np.arange(missing_df.shape[0])\n",
    "width = 0.9\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "rects = ax.barh(ind, missing_df.missing_count.values, color='blue')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\n",
    "ax.set_xlabel(\"Count of missing values\")\n",
    "ax.set_title(\"Number of missing values in each column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How much of your data is missing?\n",
    "train_df.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.drop('column_name', 1)\n",
    "to_drop = ['architecturalstyletypeid'\n",
    "           ,'assessmentyear'\n",
    "           ,'bathroomcnt'\n",
    "           ,'buildingclasstypeid'\n",
    "           ,'decktypeid'\n",
    "           ,'threequarterbathnbr'\n",
    "           ,'finishedfloor1squarefeet'\n",
    "           ,'finishedsquarefeet6'\n",
    "           ,'finishedsquarefeet12'\n",
    "           ,'finishedsquarefeet13'\n",
    "           ,'finishedsquarefeet15'\n",
    "           ,'finishedsquarefeet50'\n",
    "           ,'fireplaceflag'\n",
    "           ,'fullbathcnt'\n",
    "           ,'garagetotalsqft'\n",
    "           ,'latitude'\n",
    "           ,'longitude'\n",
    "           ,'poolsizesum'\n",
    "           ,'propertyzoningdesc'\n",
    "           ,'rawcensustractandblock'\n",
    "           ,'censustractandblock'\n",
    "           ,'regionidzip'\n",
    "           ,'storytypeid'\n",
    "           ,'typeconstructiontypeid'\n",
    "           ,'taxvaluedollarcnt'\n",
    "           ,'taxamount'\n",
    "           ,'taxdelinquencyyear'\n",
    "           ,'fips'\n",
    "           \n",
    "           ,'hashottuborspa'\n",
    "           ,'pooltypeid10'\n",
    "           ,'pooltypeid2'\n",
    "           ,'pooltypeid7'\n",
    "               \n",
    "           ,'propertycountylandusecode'   # 241 unique values, cannot dummy for size reasons          \n",
    "           ,'regionidcity'            # 187 unique values, cannot dummy for size reasons\n",
    "           ,'regionidneighborhood'    # 529 unique values, cannot dummy for size reasons\n",
    "           ,'transactiondate'\n",
    "          ]\n",
    "\n",
    "for col in to_drop:\n",
    "    train_df = train_df.drop(col,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##df['bedroomcnt'] = [0 if x <3 else 1 for x in df['bedroomcnt']] #bad example, but you get the point\n",
    "# Bin object variables in specific ways\n",
    "\n",
    "## airconditioningtypeid\n",
    "train_df['airconditioningtypeid'].fillna(value='missing',inplace=True)\n",
    "\n",
    "## bedroomcnt\n",
    "a = np.array(train_df['bedroomcnt'].values.tolist())\n",
    "train_df['bedroomcnt'] = np.where(a > 6, 6, a).tolist()\n",
    "train_df['bedroomcnt'].fillna(value=3,inplace=True) # Or maybe impute with most_common, which is 3\n",
    "\n",
    "## buildingqualitytypeid (best=lowest, worse=highest)\n",
    "\n",
    "a = np.array(train_df['buildingqualitytypeid'].values.tolist())\n",
    "train_df['buildingqualitytypeid'] = np.where(a < 4,  4, a)  #.tolist()\n",
    "a = np.array(train_df['buildingqualitytypeid'].values.tolist())\n",
    "train_df['buildingqualitytypeid'] = np.where(a > 7, 10, a)  #.tolist()\n",
    "a = np.array(train_df['buildingqualitytypeid'].values.tolist())\n",
    "train_df['buildingqualitytypeid'] = np.where(a == 5, 7, a)  #.tolist()\n",
    "a = np.array(train_df['buildingqualitytypeid'].values.tolist())\n",
    "train_df['buildingqualitytypeid'] = np.where(a == 6, 7, a).tolist()\n",
    "a = np.array(train_df['buildingqualitytypeid'].values.tolist())\n",
    "train_df['buildingqualitytypeid'].fillna(value=99,inplace=True) # 99 = missing (BE CAREFUL NOT TO CHANGE BEFORE '>' STATEMENT)\n",
    "\n",
    "## fips - we dropped this so no need to proprocess\n",
    "# train_df['fips'].fillna(value=99,inplace=True)\n",
    "\n",
    "## fireplacecnt\n",
    "a = np.array(train_df['fireplacecnt'].values.tolist())\n",
    "train_df['fireplacecnt'] = np.where(a > 3,  3, a)  #.tolist()\n",
    "train_df['fireplacecnt'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "## garagecarcnt\n",
    "a = np.array(train_df['garagecarcnt'].values.tolist())\n",
    "train_df['garagecarcnt'] = np.where(a > 3,  3, a)  #.tolist()\n",
    "train_df['garagecarcnt'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "##  hashottuborspa\n",
    "#train_df['hashottuborspa'].fillna(value=False,inplace=True) #set NaN to False\n",
    "\n",
    "## heatingorsystemtypeid\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 19,  14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 21, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 11, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 12, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 10, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a ==  1, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 18, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 13, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 20, 14, a)  #.tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "train_df['heatingorsystemtypeid'] = np.where(a == 12, 14, a).tolist()\n",
    "a = np.array(train_df['heatingorsystemtypeid'].values.tolist())\n",
    "\n",
    "train_df['heatingorsystemtypeid'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## numberofstories\n",
    "a = np.array(train_df['numberofstories'].values.tolist())\n",
    "train_df['numberofstories'] = np.where(a > 3,  3, a)  #.tolist()\n",
    "train_df['numberofstories'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## poolcnt\n",
    "train_df['poolcnt'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "## pooltypes\n",
    "#train_df['pooltypeid10'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "#train_df['pooltypeid2'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "#train_df['pooltypeid7'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "\n",
    "## propertycountylandusecode\n",
    "#### probably should loop through, has 241 distinct values, some of which have count=1\n",
    "#train_df['propertycountylandusecode'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## propertylandusetypeid\n",
    "### too many unique values, so had to drop\n",
    "train_df['propertylandusetypeid'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## regionidcounty\n",
    "train_df['regionidcounty'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## regionidcity\n",
    "#### probably should loop through, has 187 distinct values, some of which have count=1\n",
    "### too many unique values, so had to drop\n",
    "#train_df['regionidcity'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## regionidneighborhood\n",
    "#### probably should loop through, has 500+ distinct values, some of which have count=1.  Maybe use lat-long to KNN???\n",
    "### too many unique values, so had to drop\n",
    "#train_df['regionidneighborhood'].fillna(value=99,inplace=True) #set NaN to 99\n",
    "\n",
    "## calculatedbathnbr\n",
    "train_df['calculatedbathnbr'].fillna(value=2,inplace=True)  # Or maybe impute with most_common, which is 2\n",
    "\n",
    "## roomcnt\n",
    "a = np.array(train_df['roomcnt'].values.tolist())\n",
    "train_df['roomcnt0'] = np.where(a == 0, 1, 0)  #.tolist()\n",
    "train_df['roomcnt'] = np.where(a < 3,  3, a)  #.tolist()\n",
    "a = np.array(train_df['roomcnt'].values.tolist())\n",
    "train_df['roomcnt'] = np.where(a > 7, 10, a)  #.tolist()\n",
    "a = np.array(train_df['roomcnt'].values.tolist())\n",
    "train_df['roomcnt'] = np.where(a == 5, 7, a)  #.tolist()\n",
    "a = np.array(train_df['roomcnt'].values.tolist())\n",
    "train_df['roomcnt'] = np.where(a == 6, 7, a).tolist()\n",
    "a = np.array(train_df['roomcnt'].values.tolist())\n",
    "train_df['roomcnt'].fillna(value=6,inplace=True) #set NaN to 6, most common value\n",
    "\n",
    "\n",
    "## unitcnt\n",
    "a = np.array(train_df['unitcnt'].values.tolist())\n",
    "train_df['unitcnt'] = np.where(a > 5, 5, a)  #.tolist()\n",
    "train_df['unitcnt'].fillna(value=1,inplace=True) #set NaN to 1\n",
    "\n",
    "## yearbuilt    \n",
    "a = np.array(train_df['yearbuilt'].values.tolist())\n",
    "train_df['yearbuilt'] = (train_df['yearbuilt']/10).round()\n",
    "a = np.array(train_df['yearbuilt'].values.tolist())\n",
    "train_df['yearbuilt'] = np.where(a < 190, 189, a)  #.tolist()\n",
    "train_df['yearbuilt'].fillna(value=195,inplace=True) #set NaN to 195\n",
    "\n",
    "\n",
    "\n",
    "##  taxdelinquencyflag   train_df['taxdelinquencyflag'].value_counts()\n",
    "train_df['taxdelinquencyflag'] = [1 if x == 'Y' else 0 for x in train_df['taxdelinquencyflag']] \n",
    "train_df['taxdelinquencyflag'].fillna(value=0,inplace=True) #set NaN to zeroTrue) #set NaN to zero\n",
    "\n",
    "\n",
    "##  Numeric variables whose NaN we'll set to zero\n",
    "a = np.array(train_df['basementsqft'].values.tolist())\n",
    "train_df['basementsqft_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['basementsqft'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "a = np.array(train_df['calculatedfinishedsquarefeet'].values.tolist())\n",
    "train_df['calculatedfinishedsquarefeet_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['calculatedfinishedsquarefeet'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "a = np.array(train_df['lotsizesquarefeet'].values.tolist())\n",
    "train_df['lotsizesquarefeet_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['lotsizesquarefeet'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "a = np.array(train_df['yardbuildingsqft17'].values.tolist())\n",
    "train_df['yardbuildingsqft17_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['yardbuildingsqft17'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "a = np.array(train_df['yardbuildingsqft17'].values.tolist())\n",
    "train_df['yardbuildingsqft17'] = np.where(a > 0, 1, 0)  #.tolist()\n",
    "\n",
    "a = np.array(train_df['yardbuildingsqft26'].values.tolist())\n",
    "train_df['yardbuildingsqft26_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['yardbuildingsqft26'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "a = np.array(train_df['yardbuildingsqft26'].values.tolist())\n",
    "train_df['yardbuildingsqft26'] = np.where(a > 0, 1, 0)  #.tolist()\n",
    "\n",
    "a = np.array(train_df['structuretaxvaluedollarcnt'].values.tolist())\n",
    "train_df['structuretaxvaluedollarcnt_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['structuretaxvaluedollarcnt'].fillna(value=0,inplace=True) #set NaN to zero\n",
    "\n",
    "a = np.array(train_df['landtaxvaluedollarcnt'].values.tolist())\n",
    "train_df['landtaxvaluedollarcnt_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['landtaxvaluedollarcnt'].fillna(value=10000,inplace=True) #set NaN to 10000\n",
    "\n",
    "a = np.array(train_df['calculatedfinishedsquarefeet'].values.tolist())\n",
    "train_df['calculatedfinishedsquarefeet_NaN'] = np.where(a == np.NaN, 1, 0)  #.tolist()\n",
    "train_df['calculatedfinishedsquarefeet'].fillna(value=6000,inplace=True) #set NaN to 6000, most common number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAQPCAYAAAADP2MvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116dea310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Missing values again, after processing attempt to remove some fields and assign a value to others' NaN values\n",
    "missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "\n",
    "ind = np.arange(missing_df.shape[0])\n",
    "width = 0.9\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "rects = ax.barh(ind, missing_df.missing_count.values, color='blue')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\n",
    "ax.set_xlabel(\"Count of missing values\")\n",
    "ax.set_title(\"Number of missing values in each column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "objs = [ 'airconditioningtypeid'\n",
    "        ,'bedroomcnt'\n",
    "        ,'buildingqualitytypeid'\n",
    "        ,'fireplacecnt'\n",
    "        ,'garagecarcnt'\n",
    "        ,'heatingorsystemtypeid'\n",
    "        ,'numberofstories'\n",
    "        ,'poolcnt'        \n",
    "        ,'propertylandusetypeid'   \n",
    "        ,'regionidcounty'\n",
    "        ,'unitcnt'\n",
    "        ,'yearbuilt'   \n",
    "        ,'taxdelinquencyflag'  \n",
    "        ,'yardbuildingsqft17'\n",
    "        ,'yardbuildingsqft26'        \n",
    "        ]\n",
    "\n",
    "\n",
    "for obj in objs:\n",
    "    train_df[obj] = train_df[obj].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "flts = [ 'basementsqft'\n",
    "        ,'calculatedbathnbr'\n",
    "        ,'calculatedfinishedsquarefeet'\n",
    "        ,'landtaxvaluedollarcnt'\n",
    "        ,'lotsizesquarefeet'\n",
    "        ,'roomcnt'\n",
    "        ,'structuretaxvaluedollarcnt'\n",
    "       ]\n",
    "\n",
    "for flt in flts:\n",
    "    train_df[flt] = train_df[flt].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'airconditioningtypeid' has 7 unique categories\n",
      "Feature 'bedroomcnt' has 7 unique categories\n",
      "Feature 'buildingqualitytypeid' has 4 unique categories\n",
      "Feature 'fireplacecnt' has 4 unique categories\n",
      "Feature 'garagecarcnt' has 5 unique categories\n",
      "Feature 'heatingorsystemtypeid' has 6 unique categories\n",
      "Feature 'poolcnt' has 2 unique categories\n",
      "Feature 'propertylandusetypeid' has 14 unique categories\n",
      "Feature 'regionidcounty' has 3 unique categories\n",
      "Feature 'unitcnt' has 5 unique categories\n",
      "Feature 'yardbuildingsqft17' has 2 unique categories\n",
      "Feature 'yardbuildingsqft26' has 2 unique categories\n",
      "Feature 'yearbuilt' has 14 unique categories\n",
      "Feature 'numberofstories' has 4 unique categories\n",
      "Feature 'taxdelinquencyflag' has 2 unique categories\n"
     ]
    }
   ],
   "source": [
    "# Decide which categorical variables you want to use in model\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtypes == 'object':       \n",
    "        unique_cat = len(train_df[col].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} unique categories\".format(col_name=col, unique_cat=unique_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummy list\n",
    "to_dummy = [ 'airconditioningtypeid'\n",
    "            ,'bedroomcnt'\n",
    "            ,'buildingqualitytypeid'\n",
    "            ,'fireplacecnt'\n",
    "            ,'garagecarcnt'\n",
    "            ,'heatingorsystemtypeid'\n",
    "            ,'numberofstories'\n",
    "            ,'poolcnt'\n",
    "            ,'propertylandusetypeid'   \n",
    "            ,'regionidcounty'         \n",
    "            ,'unitcnt'\n",
    "            ,'yearbuilt'   \n",
    "            ,'taxdelinquencyflag'  \n",
    "            ,'yardbuildingsqft17'\n",
    "            ,'yardbuildingsqft26'   \n",
    "            ,'transaction_month'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this function to dummy all the categorical variables we want to keep\n",
    "def dummy_df(df, todummy_list):\n",
    "    for x in todummy_list:       \n",
    "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=True)\n",
    "        df = df.drop(x, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## bool  \n",
    "train_df = dummy_df(train_df, to_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Analysis into Extreme Log Errors </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This competition is focused on predicting the log error of predicted versus transaction prices. As shown in the graph in EDA section and recreated below, the vast majority of log errors are quite low. It is in the extreme values where the error rates increase drastically. Therefore, we will perform an analysis on just these extreme values to see if there are any patterns that will help us identify these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "# create a mask for values less than -.1 and greater than .1\n",
    "masked = np.ma.masked_outside(np.sort(train_df.logerror.values), -.1, .1)\n",
    "# plot masked and non-masked values\n",
    "plt.plot(range(train_df.shape[0]), np.sort(train_df.logerror.values), 'red')\n",
    "plt.plot(range(train_df.shape[0]), masked, 'blue')\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('logerror', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_error_df= train_df[(train_df.logerror <-.1) | (train_df.logerror >.1)]\n",
    "low_error_df = train_df[(train_df.logerror>=-.1) & (train_df.logerror<=.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll visualize the log errors by month of transaction to see if there are any seasonal effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt_srs = high_error_df['transaction_month'].value_counts()\n",
    "plt.figure(figsize=(12,6))\n",
    "bars= sns.barplot(cnt_srs.index, cnt_srs.values,  color=color[2])\n",
    "plt.xticks()\n",
    "plt.xlabel('Month of transaction', fontsize=12)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.title('Number of Transactions per Month- High Error Data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "cnt_srs = low_error_df['transaction_month'].value_counts()\n",
    "plt.figure(figsize=(12,6))\n",
    "bars= sns.barplot(cnt_srs.index, cnt_srs.values,  color=color[2])\n",
    "plt.xticks()\n",
    "plt.xlabel('Month of transaction', fontsize=12)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.title('Number of Transactions per Month- All Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These charts tend to follow the same pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_error_df.ix[:, 0:10].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_error_df.ix[:, 0:10].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the differences in the high errors and low errors dataframes, we observe the following differences:\n",
    "\n",
    "__Calculated Finished Square Feet:__ The low error transactions have a mean value of 1739 sqft with a standard deviation of 876sqft.  The high error transactions have a high mean value of 1870 sqft with a higher standard deviation of 1197. \n",
    "\n",
    "<b> Structure Tax Value Dollar Count </b> The high error transactions have a higher mean (192253 vs 176848) and a higher standard deviation (310239 vs 183111) than low error transactions.\n",
    "\n",
    "<b> Land Tax Value Dollar Count </b> Similar to the structure tax value dollar count, the mean land value dollar count is higher for high error transactions (322560 vs 269816) and has a higher standard deviation (641348 vs 334122).\n",
    "\n",
    "<b> FIPS </b> The FIPS indicates the county of the home.  In the high error data, 73.8% of the homes are in Los Angeles County, 19% are in Orange County, and 6.7% are in Ventura County.  In the low error data, 63% are in Los Angeles County, 28% are in Orange County, and 8.2% are in Ventura County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2> K-Nearest Neighbors </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors is a classification model which predicts the classification of an unclassified data point based upon the values of it's closest k neighbors. Therefore, when k=1, the model will predict the value based upon the cloest neighbor. When k= 9, the model will find the new data points 9 closest neighbors and determine the majority classification of those nine points. The majority classification will be imputed to the unclassified data point.\n",
    "Here, we are attempting to classify whether an property value will result in a large positive error, a low error, or a large negative error. By classifying the type of error, we can help direct our final model towards a specific predicted error value, thus lowering the MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a copy of the train_data so that we cam make changes\n",
    "classifier_data = train_df.copy()\n",
    "\n",
    "classifier_data['logerror'].loc[classifier_data['logerror']>=.1] = 1\n",
    "classifier_data['logerror'].loc[classifier_data['logerror']<= -.1] = -1\n",
    "classifier_data['logerror'].loc[(classifier_data['logerror']>-.1) & (classifier_data['logerror']<.1)] = 0\n",
    "\n",
    "train_np = classifier_data.values\n",
    "Y = train_np[:,0]\n",
    "Y.flatten()\n",
    "X =train_np[:,1:]\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape: ', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "classifier_test_data, classifier_test_labels = X[70000:], Y[70000:]\n",
    "classifier_train_data, classifier_train_labels = X[:70000], Y[:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Originally ran with k values range (1,200,20), but little to no increase after k>20\n",
    "k_values = range(10,32, 2)\n",
    "for k in k_values:\n",
    "    #initialize and train the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(classifier_train_data, classifier_train_labels)\n",
    "    accuracy= clf.score(classifier_test_data, classifier_test_labels)\n",
    "    predictions = clf.predict(classifier_test_data)\n",
    "    \n",
    "    #Uncomment code below and comment out if statement above to get classification report for all k values\n",
    "#     print(\"Classification Report for k =\" + str(k))\n",
    "#     print(classification_report(knn_test_labels.astype(int),predictions))\n",
    "# For all k values, print the accuracy\n",
    "    print(\"K: \" + str(k) + \" Accuracy: \" + str(accuracy))\n",
    "    if k == 30:\n",
    "        print(\"Classification Report for k = {}\".format(k))\n",
    "        print(classification_report(classifier_test_labels.astype(int),predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Results: </b> While the accuracy of this model in classifying whether the outcome will be a large positive error (1), a low error (0), or a large negative error(-1) is approximately 84%, this K-Nearest Neighbors classifier performance is quite poor. The printed classification report is for the k=1 model, but the reports for higher k models show the same general issues  \n",
    "\n",
    "The precision column indicates the positive predictive value, which is calculated by the number of true positives divided by the number of true positives plus false positives.  In our situation, the precision measures the percentage of predictions that our model predicted to be 1s that were actually 1s.  As you can see, the precision of this model is low at 25% values that extreme highs and 0% for extreme lows.  This classifier performs very poorly for precision. \n",
    "\n",
    "The recall column indicates the sensitivity of the model.  It is calculated by taking the ratio of true positive results divided by the sum of true positives and false negatives.  In this situation, recall measures the percentage of 1s that our model identifies out of all 1s it should have identified. In our model, the recall is 0% for the extreme log errors that we are trying to classify.  \n",
    "\n",
    "The f1-score is the weighted harmonic mean of the precision and recall and gives an understanding of the overall power of the classifier. \n",
    "\n",
    "Due to the relatively small amount of extreme results in our data, this classifier tends to overpredict results of 0.  As a result, we end up with high accuracy, but poor precision and recall.  Therefore, we will not add the results of this classifier into our dataset for our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Naive Bayes </h2>\n",
    "\n",
    "Naive Bayes methods are supervised learning algorithms that apply Bayes' Theorem with the assumption of independence between each pair of features.  While we know that we do not have independence between each pair of features in our data, in practice, Naive Bayes has worked well in datasets that violate this assumption.  \n",
    "\n",
    "The SKLearn package supports three distinct Naive Bayes models.  The first is Gaussian Naive Bayes model.  This model assumes the likelihood of the features is distributed like a Gaussian, or normal, distribution.  The second supported model is the Multinomial Naive Bayes model.  The multinomial model is for multinomially distributed data and is best suited for data that can be turned into counts- such as text classification with word counts.  The final model is the Bernoulli Naive Bayes model, which is used with data distributed similar to a multivariate Bernoulli Distribution.  Each feature in a Bernoulli model is assumed to be binary.  \n",
    "\n",
    "More information about SKLearn Naive Bayes models can be located here: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Since our data can be best classified as normally distributed and is not binary and is not well suited for a multinomial distribution, we will use a Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize model and test accuracy of multinomial naive bayes classifier\n",
    "gauss_nb = GaussianNB()\n",
    "gauss_nb.fit(classifier_train_data, classifier_train_labels)\n",
    "nb_accuracy = gauss_nb.score(classifier_test_data, classifier_test_labels)\n",
    "print(\"Accuracy of Gaussian Naive Bayes Model: {}\".format(round(nb_accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainknn= train_df.copy()\n",
    "# #['airconditioningtypeid', 'parcelid','taxdelinquencyflag','transactiondate', 'propertycountylandusecode']\n",
    "\n",
    "# ulimit = np.percentile(trainknn.logerror.values, 99)\n",
    "# llimit = np.percentile(trainknn.logerror.values, 1)\n",
    "# trainknn['logerror'].loc[trainknn['logerror']>=ulimit] = 1\n",
    "# trainknn['logerror'].loc[trainknn['logerror']<=llimit] = -1\n",
    "# trainknn['logerror'].loc[(trainknn['logerror']>llimit) & (trainknn['logerror']<ulimit)] = 0\n",
    "\n",
    "# train_np = trainknn.values\n",
    "# Y_knn = train_np[:,0]\n",
    "# Y_knn.flatten()\n",
    "# X_knn =train_np[:,1:]\n",
    "\n",
    "# shuffle = np.random.permutation(np.arange(X_knn.shape[0]))\n",
    "# X_knn, Y_knn = X_knn[shuffle], Y_knn[shuffle]\n",
    "\n",
    "# print('data shape: ', X_knn.shape)\n",
    "# print('label shape: ', Y_knn.shape)\n",
    "\n",
    "# # Set some variables to hold test, dev, and training data.\n",
    "# train_data_knn, train_labels_knn = X_knn[:50000], Y_knn[:50000]\n",
    "# dev_data_knn, dev_labels_knn = X_knn[50000:70000], Y_knn[50000:70000]\n",
    "# test_data_knn, test_labels_knn = X_knn[70000:], Y_knn[70000:]\n",
    "\n",
    "\n",
    "# pca_knn = PCA(n_components=3)\n",
    "# pca_knn.fit(train_data_knn)\n",
    "# train_data_pca_knn = pca_knn.transform(train_data_knn) \n",
    "# dev_data_pca_knn = pca_knn.transform(dev_data_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k_values = range(1,20)\n",
    "# for i in k_values:\n",
    "#     #initialize and train the classifier\n",
    "#     clf = KNeighborsClassifier(n_neighbors = i)\n",
    "#     clf.fit(train_data_pca_knn, train_labels_knn.astype(int))\n",
    "#     accuracy= clf.score(dev_data_pca_knn, dev_labels_knn.astype(int))\n",
    "#     predictions = clf.predict(dev_data_pca_knn)\n",
    "#     ## if k = 1, then print the classification report\n",
    "#     if i == 10:\n",
    "#         print(\"Classification Report for k =\" + str(i))\n",
    "#         print(classification_report(dev_labels_knn.astype(int),predictions))\n",
    "#     # For all k values, print the accuracy\n",
    "#     print(\"K: \" + str(i) + \" Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ML Start </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data shape: ', (90275, 124))\n",
      "('label shape: ', (90275,))\n"
     ]
    }
   ],
   "source": [
    "# split data into training and dev sets. We don't need test sets since that is done on the Kaggle website\n",
    "train_np = train_df.values\n",
    "Y = train_np[:,1]\n",
    "Y.flatten()\n",
    "X = train_np[:,2:]\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape: ', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "train_data, train_labels = X[:70000], Y[:70000]\n",
    "dev_data, dev_labels = X[70000:], Y[70000:]\n",
    "\n",
    "#definite MAE (Mean Absolute Error) function\n",
    "def MAE(test_labels, predictions):\n",
    "    values = []\n",
    "    for i in range(len(test_labels)):\n",
    "        difference = abs(round(test_labels[i],6) - round(predictions[i],6))\n",
    "        values.append(difference)\n",
    "    mean_abs_error = round(sum(values)/len(values),7)\n",
    "    return mean_abs_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 112)\n"
     ]
    }
   ],
   "source": [
    "properties_df = pd.read_csv(\"preprocessed_properties.csv\")\n",
    "print properties_df.shape\n",
    "\n",
    "# convert to array and remove parcelIDs\n",
    "properties_np = properties_df.values\n",
    "parcelids = properties_np[:, 0]\n",
    "props_to_model = properties_np[:, 1:]\n",
    "\n",
    "# function to create Kaggle submission files \n",
    "def get_submission_file(parcelids, oct_est, nov_est, dec_est):\n",
    "    submission_array = np.vstack((parcelids, oct_est, nov_est, dec_est, oct_est, nov_est, dec_est))\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_array.T)\n",
    "    submission_df.rename(columns={0: 'ParcelId',\n",
    "                                  1: '201610',\n",
    "                                  2: '201611',\n",
    "                                  3: '201612',\n",
    "                                  4: '201710',\n",
    "                                  5: '201711',\n",
    "                                  6: '201712'\n",
    "                                 }, inplace=True)\n",
    "    \n",
    "    submission_df[\"ParcelId\"] = submission_df[\"ParcelId\"].astype(int)\n",
    "    submission_df.to_csv(\"Zillow_submission_file.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create arrays to represent months Oct, Nov, Dec\n",
    "# note: our months are dummy variables\n",
    "rows = props_to_model.shape[0]\n",
    "october = np.hstack((np.zeros((rows,9)), np.ones((rows,1)), np.zeros((rows,3))))\n",
    "november = np.hstack((np.zeros((rows,10)), np.ones((rows,1)), np.zeros((rows,2))))\n",
    "december = np.hstack((np.zeros((rows,11)), np.ones((rows,1)), np.zeros((rows,1))))\n",
    "\n",
    "submission_setup_oct = np.hstack((props_to_model, october))\n",
    "submission_setup_nov = np.hstack((props_to_model, november))\n",
    "submission_setup_dec = np.hstack((props_to_model, december))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression gives us a Mean Absolute Error of 0.068632\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "lm = LinearRegression()\n",
    "lm.fit(train_data, train_labels)\n",
    "lm_predict = lm.predict(dev_data)\n",
    "\n",
    "lm_mae = MAE(dev_labels, lm_predict)\n",
    "print \"Linear Regression gives us a Mean Absolute Error of\", lm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 7)\n"
     ]
    }
   ],
   "source": [
    "# predict final outputs\n",
    "lm_subm_oct = lm.predict(submission_setup_oct)\n",
    "lm_subm_nov = lm.predict(submission_setup_nov)\n",
    "lm_subm_dec = lm.predict(submission_setup_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_submission_file(parcelids, lm_subm_oct, lm_subm_nov, lm_subm_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = range(5,30)\n",
    "lowest_mae = 1\n",
    "results = []\n",
    "for i in estimators:\n",
    "    gboost = GradientBoostingRegressor(n_estimators=i) \n",
    "    gboost.fit(train_data, train_labels)\n",
    "    gboost_predict = gboost.predict(dev_data)\n",
    "\n",
    "    mae = MAE(dev_labels, gboost_predict)\n",
    "    results.append(mae)\n",
    "    \n",
    "    if mae < lowest_mae:\n",
    "        lowest_mae = mae\n",
    "        best_estimator = i\n",
    "print \"Best estimator=%d, MAE=%7.6f\" % (best_estimator, lowest_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(min(results))\n",
    "plt.plot(estimators, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a technique used to reduce high dimensionality data. High dimensionality data is problematic because as it acts as a multiplier to the feature space. For example, consider the area of a 10x10 coordinate system. The feature space has an area of 100 square units. If you add a z dimension of size 10 to the data, the volume becomes 1000 cubed units. Continuing to add more dimensions continues to multiply the size of the feature space which makes the data relatively sparse. This is the curse of dimensionality.\n",
    "PCA combats the curse of dimensionality by finding new dimensions that reduce the dimensionality of the data while minimizing the loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(train_data)\n",
    "for k in range(1,11):\n",
    "    explained_var = pca.explained_variance_ratio_[0:k]\n",
    "    print \"k=\" + str(k) + \", explained variance =\", sum(explained_var)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3 PCA components is probably best. This gives us >99.99% explained variance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k= 10\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(classifier_data)\n",
    "\n",
    "# Create list of cumulative sum of variances explained\n",
    "var_exp = np.cumsum(pca.explained_variance_ratio_)\n",
    "var_exp_single = pca.explained_variance_ratio_\n",
    "print(\"Total variance explained by first 50 principal components\")\n",
    "for i in range(1, k+1):\n",
    "    print(\"k: \" + str(i) + \" Variance Explained: \" + str(round(var_exp[i-1], 7)))\n",
    "\n",
    "# Plot of variance explained\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(range(1, k+1), var_exp_single[:50])\n",
    "plt.ylabel(\"Variance Explained\")\n",
    "plt.xlabel(\"Component\")\n",
    "plt.title(\"Explained Variance by PCA Component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_data = pca.fit_transform(classifier_data)\n",
    "\n",
    "x1=pca_data[:,0][classifier_train_labels==1]\n",
    "y1= pca_data[:,1][classifier_train_labels==1]\n",
    "z1= pca_data[:,2][classifier_train_labels==1]\n",
    "\n",
    "x2= pca_data[:,0][classifier_train_labels == -1]\n",
    "y2=pca_data[:,1][classifier_train_labels==-1]\n",
    "z2=pca_data[:,2][classifier_train_labels==-1]\n",
    "\n",
    "x3= pca_data[:,0][classifier_train_labels==0]\n",
    "y3= pca_data[:,1][classifier_train_labels==0]\n",
    "z3= pca_data[:,2][classifier_train_labels==0]\n",
    "\n",
    "#plot PCA data\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(x1, y1, z1, color = 'red', label = 'Large Positive Error', alpha = .5)\n",
    "ax.scatter(x2, y2, z2, color = 'blue', label = 'Large Negative Error', alpha = .5)\n",
    "ax.scatter(x3, y3, z3, color = 'green', label = 'Small Error', alpha= .5)\n",
    "\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "\n",
    "plt.legend(loc=\"best\", fontsize = 12)\n",
    "plt.title(\"3-D Projection of Log Errors Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_values = range(1,21)\n",
    "for k in k_values:\n",
    "    #initialize and train the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(pca_classifier_train_data, pca_classifier_train_labels)\n",
    "    accuracy= clf.score(pca_classifier_test_data, pca_classifier_test_labels)\n",
    "    predictions = clf.predict(pca_classifier_test_data)\n",
    "    \n",
    "    #Uncomment code below and comment out if statement above to get classification report for all k values\n",
    "#     print(\"Classification Report for k =\" + str(k))\n",
    "#     print(classification_report(knn_test_labels.astype(int),predictions))\n",
    "# For all k values, print the accuracy\n",
    "    print(\"K: \" + str(k) + \" Accuracy: \" + str(accuracy))\n",
    "    if k == 15:\n",
    "        print(\"Classification Report for k = {}\".format(k))\n",
    "        print(classification_report(classifier_test_labels.astype(int),predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA, we do not notice an increase KNN Accuracy. Additionally, we notice worse precision and recall (0%) for the extreme values that we are trying to identify. The KNN model still provides no value for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize model and test accuracy of multinomial naive bayes classifier\n",
    "mult_nb = GaussianNB()\n",
    "mult_nb.fit(pca_classifier_train_data, pca_classifier_train_labels)\n",
    "nb_accuracy = mult_nb.score(pca_classifier_test_data, pca_classifier_test_labels)\n",
    "print(\"Accuracy of Multinomial Naive Bayes Model: {}\".format(round(nb_accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator=4, MAE=0.068591\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(train_data)\n",
    "train_data_pca = pca.transform(train_data) \n",
    "dev_data_pca = pca.transform(dev_data) \n",
    "\n",
    "estimators = range(1,20)\n",
    "lowest_mae = 1\n",
    "results = []\n",
    "for i in estimators:\n",
    "    gboost = GradientBoostingRegressor(n_estimators=i) \n",
    "    gboost.fit(train_data_pca, train_labels)\n",
    "    gboost_predict = gboost.predict(dev_data_pca)\n",
    "\n",
    "    mae = MAE(dev_labels, gboost_predict)\n",
    "    results.append(mae)\n",
    "    \n",
    "    if mae < lowest_mae:\n",
    "        lowest_mae = mae\n",
    "        best_estimator = i\n",
    "print \"Best estimator=%d, MAE=%7.6f\" % (best_estimator, lowest_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113c47950>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1140c4c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(min(results))\n",
    "plt.plot(estimators, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using PCA with GradientBoostRegression doesn't help to reduce the MAE. We got 0.068703 before PCA and 0.068718 after. While it doesn't reduce MAE here, maybe it is still better for generalizability? (Maybe not, open to suggestions). PCA also reduced runtime from 20 minutes down to less than 30 seconds.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spca = SparsePCA(n_components = 10, alpha=0.5, tol=0.001)\n",
    "spca.fit(train_data)\n",
    "for k in range(1,11):\n",
    "    explained_var = pca.explained_variance_ratio_[0:k]\n",
    "    print \"k=\" + str(k) + \", explained variance =\", sum(explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spca = SparsePCA(n_components = 3, alpha=0.5, tol=0.001)\n",
    "spca.fit(train_data)\n",
    "train_data_spca = spca.transform(train_data) \n",
    "dev_data_spca = spca.transform(dev_data) \n",
    "\n",
    "estimators = range(1,25)\n",
    "lowest_mae = 1\n",
    "results = []\n",
    "for i in estimators:\n",
    "    gboost = GradientBoostingRegressor(n_estimators=i) \n",
    "    gboost.fit(train_data_spca, train_labels)\n",
    "    gboost_predict = gboost.predict(dev_data_spca)\n",
    "\n",
    "    mae = MAE(dev_labels, gboost_predict)\n",
    "    results.append(mae)\n",
    "    \n",
    "    if mae < lowest_mae:\n",
    "        lowest_mae = mae\n",
    "        best_estimator = i\n",
    "print \"Best estimator=%d, MAE=%7.6f\" % (best_estimator, lowest_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(min(results))\n",
    "plt.plot(estimators, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using SparcePCA with GradientBoostRegression doesn't help to reduce the MAE either. We got 0.068703 before SparsePCA and 0.068724 after. SparsePCA performed slightly worse than regular PCA (0.068718) as well. The PCA models ran much faster, so maybe they're still useful.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(criterion=\"mae\")\n",
    "dtr.fit(train_data_pca, train_labels)\n",
    "dtr_preds = dtr.predict(dev_data_pca)\n",
    "dtr_mae = MAE(dev_labels, dtr_preds)\n",
    "print 'DecisionTreeRegressor MAE =', dtr_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(criterion=\"mae\", n_estimators=5)\n",
    "rfr.fit(train_data_pca, train_labels)\n",
    "rfr_preds = rfr.predict(dev_data_pca)\n",
    "mae = MAE(dev_labels, rfr_preds)\n",
    "print 'RandomForestRegressor MAE =', mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# LR1 = LogisticRegression(penalty='l2', tol=0.0001, fit_intercept=True, intercept_scaling=1\n",
    "#                               , solver='newton-cg', multi_class='multinomial')\n",
    "# ### GridSearchCV to find best C using l2 regularization.  \n",
    "# ## Using [float(2**i)/100 for i in range(1,20) ] ...\n",
    "# LR1_para = {'C': [0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1.28, 2.56, 5.12, 10.24, 20.48, \n",
    "#                        40.96, 81.92, 163.84, 327.68, 655.36, 1310.72, 2621.44, 5242.88] }\n",
    "# LR1_GS = GridSearchCV(estimator=LR1, param_grid=LR1_para, scoring='f1', n_jobs=-1)\n",
    "# LR1_GS.fit(train_data, train_labels)\n",
    "# print(\"Start LogisticRegression:\")\n",
    "# print(LR1_GS.best_score_)\n",
    "# print(LR1_GS.best_params_)\n",
    "# # print(\"f1:\",metrics.f1_score(dev_labels,LR1_GS.best_estimator_.predict(dev_data),average='micro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zipped = zip(train_df.columns, spca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spca.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "Check SparsePCA which features are dropped\n",
    "Model different months. Drop months before PCA, do PCA, then add months back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 124)\n",
      "(70000, 111)\n",
      "(70000, 13)\n",
      "\n",
      "(20275, 124)\n",
      "(70000, 111)\n",
      "(70000, 13)\n"
     ]
    }
   ],
   "source": [
    "train_data_no_months = np.delete(train_data, range(111,124), axis=1)\n",
    "train_months = np.delete(train_data, range(0,111), axis=1)\n",
    "dev_data_no_months = np.delete(train_data, range(111,124), axis=1)\n",
    "dev_months = np.delete(train_data, range(0,111), axis=1)\n",
    "\n",
    "print train_data.shape\n",
    "print train_data_no_months.shape\n",
    "print train_months.shape\n",
    "print ''\n",
    "print dev_data.shape\n",
    "print dev_data_no_months.shape\n",
    "print dev_months.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator=1, MAE=0.068619\n"
     ]
    }
   ],
   "source": [
    "# TESTING REMOVING MONTHS AND RE-ADDING\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(train_data_no_months)\n",
    "train_data_pca = pca.transform(train_data_no_months) \n",
    "dev_data_pca = pca.transform(dev_data_no_months) \n",
    "\n",
    "train_data_final = np.hstack((train_data_pca, train_months))\n",
    "dev_data_final = np.hstack((dev_data_pca, dev_months))\n",
    "\n",
    "estimators = range(1,15)\n",
    "lowest_mae = 1\n",
    "results = []\n",
    "for i in estimators:\n",
    "    gboost = GradientBoostingRegressor(n_estimators=i) \n",
    "    gboost.fit(train_data_final, train_labels)\n",
    "    gboost_predict = gboost.predict(dev_data_final)\n",
    "\n",
    "    mae = MAE(dev_labels, gboost_predict)\n",
    "    results.append(mae)\n",
    "    \n",
    "    if mae < lowest_mae:\n",
    "        lowest_mae = mae\n",
    "        best_estimator = i\n",
    "print \"Best estimator=%d, MAE=%7.6f\" % (best_estimator, lowest_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x113e45650>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113bbf5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(min(results))\n",
    "plt.plot(estimators, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gboost = GradientBoostingRegressor(n_estimators=30) \n",
    "# gboost.fit(train_data, train_labels)\n",
    "# gboost_predict = gboost.predict(dev_data)\n",
    "\n",
    "# print MAE(dev_labels, gboost_predict)\n",
    "# print gboost.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
